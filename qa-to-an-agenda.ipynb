{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import load_tools,Tool\n",
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from langchain.agents import initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb_resource=boto3.resource('dynamodb')\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")\n",
    "kendra_client=boto3.client(service_name='kendra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_name_active_connections = os.environ.get('TABLE_CONNECTIONS')\n",
    "table_name = \"SessionTable\"\n",
    "table_name_agenda = \"QaToAnAgendaStack-TblReInventAgendaB6AA89B7-1O9IOB868HBRH\"\n",
    "kendra_index_id = \"04a17bad-8a17-4893-8f62-75341e5e789e\"\n",
    "lambda_query_function_name = \"QaToAnAgendaStack-FndynamodbqueryC2D26368-RxuymCNMoCBm\"\n",
    "bedrock_embedding_model_id = 'amazon.titan-embed-text-v1'\n",
    "model_id = \"anthropic.claude-instant-v1\"\n",
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = Bedrock(model_id=model_id, model_kwargs=model_parameter,client=boto3_bedrock)\n",
    "tools = load_tools(\n",
    "                        [\"awslambda\"],\n",
    "                        awslambda_tool_name=\"search-session-id-information\",\n",
    "                        awslambda_tool_description=\"useful for searching session information data by their ID number, only send the ID number\",\n",
    "                        function_name=lambda_query_function_name,\n",
    "                    )\n",
    "#table_name = os.environ.get(\"TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendra_ask(kendra_index_id,llm):\n",
    "    retriever = AmazonKendraRetriever(index_id=kendra_index_id)\n",
    "    memory_kendra = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True,ai_prefix=\"A\",human_prefix=\"H\")\n",
    "\n",
    "\n",
    "    Kendra_prompt_template = \"\"\"Human: You are an Agenda re:Invent 2023 Assistant. \n",
    "    You are talkative and provides specific details from its context.\n",
    "    If the AI does not know the answer to a question, it truthfully says it \n",
    "    does not know.\n",
    "\n",
    "    Assistant: OK, got it, I'll be a talkative truthful AI assistant.\n",
    "\n",
    "    Human: Here are a few documents in <documents> tags:\n",
    "    <documents>\n",
    "    {context}\n",
    "    </documents>\n",
    "    Based on previous documents, provide a list of data for each documents (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me to: {question}\n",
    "\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=Kendra_prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    condense_qa_template_kendra = \"\"\"{chat_history}\n",
    "    Human:\n",
    "    Given the previous conversation and a follow up question below, based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me.\n",
    "    Follow Up Question: {question}\n",
    "    Standalone Question:\n",
    "\n",
    "    Assistant:\"\"\"\n",
    "    standalone_question_prompt_kendra = PromptTemplate.from_template(condense_qa_template_kendra)\n",
    "\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm, \n",
    "        retriever=retriever, \n",
    "        condense_question_prompt=standalone_question_prompt_kendra, \n",
    "        return_source_documents=False, \n",
    "        combine_docs_chain_kwargs={\"prompt\":PROMPT},\n",
    "        memory = memory_kendra,\n",
    "        verbose=True)\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_tools(qa,tools):\n",
    "    tools.append(\n",
    "    Tool.from_function(\n",
    "        func=qa.run,\n",
    "        name=\"re-invent-agenda-2023\",\n",
    "        description=\"useful when you want search sessions in re:Invent 2023 agenda. This will output documentation in text type, and /n, you must deliver a coherent and accurate response from all the documentation provided. \",\n",
    "    )\n",
    "    )\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: You are an Agenda re:Invent 2023 Assistant. \n",
      "    You are talkative and provides specific details from its context.\n",
      "    If the AI does not know the answer to a question, it truthfully says it \n",
      "    does not know.\n",
      "\n",
      "    Assistant: OK, got it, I'll be a talkative truthful AI assistant.\n",
      "\n",
      "    Human: Here are a few documents in <documents> tags:\n",
      "    <documents>\n",
      "    Document Title: BOA210_Generative_AI_Asking_for_a_friend.txt\n",
      "Document Excerpt: \n",
      "November, 29 2023 16:30:00 -0500 locationname: South Seas F floorplanname: Level 3 | South venuename: Mandalay Bay sessiontype: Breakout Session description: As artificial intelligence permeates modern life, generative models are increasingly applied in various fields from art to science. However, many people still have basic questions or concerns about this fast-paced innovation. This session breaks down the complexities, starting with an easy-to-understand introduction to generative AI. Hear key topics and answers to those simple-yet-unasked questions, providing a welcoming environment for learning. Gain a deeper understanding of generative AI to confidently navigate the future of technology. This session caters to tech enthusiasts, professionals updating their knowledge, or anyone intrigued by generative AI title: Generative AI: Asking for a friend sessionuid: 16BF6665-2019-4ABF-85DF-90EF7156A771 thirdpartyid: BOA210 speakers This session caters to tech enthusiasts, professionals updating their knowledge, or anyone intrigued by generative AI title: Generative AI: Asking for a friend sessionuid: 16BF6665-2019-4ABF-85DF-90EF7156A771 thirdpartyid: BOA210 speakers: firstName_0: Mike, lastName_0: Chambers tag_name: Amazon CodeWhisperer, Services, 200 - Intermediate, Level, BuildOn.AWS, Area of Interest, Amazon Bedrock, Services, Wednesday, Day, Mandalay Bay, Venue, AI/ML, Topic, Generative AI, Area of Interest\n",
      "\n",
      "\n",
      "Document Title: BOA210_Generative_AI_Asking_for_a_friend.txt\n",
      "Document Excerpt: \n",
      "Bedrock, Services, Wednesday, Day, Mandalay Bay, Venue, AI/ML, Topic, Generative AI, Area of Interest, , speakers :firstName_0: Mike, lastName_0: Chambers, , thirdpartyid :BOA210, sessionuid :16BF6665-2019-4ABF-85DF-90EF7156A771, title :Generative AI: Asking for a friend, description :As artificial intelligence permeates modern life, generative models are increasingly applied in various fields from art to science. However, many people still have basic questions or concerns about this fast-paced innovation. This session breaks down the complexities, starting with an easy-to-understand introduction to generative AI. Hear key topics and answers to those simple-yet-unasked questions, providing a welcoming environment for learning. Gain a deeper understanding of generative AI to confidently navigate the future of technology. This session caters to tech enthusiasts, professionals updating their knowledge, or anyone intrigued by generative AI., sessiontype :Breakout Session, venuename :Mandalay Bay, floorplanname :Level 3 | South, locationname :South Seas F, startdatetimeutc :November, 29 2023 16:30:00 -0500, enddatetimeutc :November, 29 2023 17:30:00 -0500, enddatetimeutc: November, 29 2023 17:30:00 -0500 startdatetimeutc: Gain a deeper understanding of generative AI to confidently navigate the future of technology. This session caters to tech enthusiasts, professionals updating their knowledge, or anyone intrigued by generative AI., sessiontype :Breakout Session, venuename :Mandalay Bay, floorplanname :Level 3 | South, locationname :South Seas F, startdatetimeutc :November, 29 2023 16:30:00 -0500, enddatetimeutc :November, 29 2023 17:30:00 -0500, enddatetimeutc: November, 29 2023 17:30:00 -0500 startdatetimeutc: November, 29 2023 16:30:00 -0500 locationname: South Seas F floorplanname: Level 3 | South venuename: Mandalay Bay sessiontype: Breakout Session description: As artificial intelligence permeates modern life, generative models are increasingly applied in various fields from art to science. However, many people still have basic questions or concerns about this fast-paced innovation.\n",
      "\n",
      "\n",
      "Document Title: CMP209_Generative_AI_panel_Moving_beyond_the_hype_and_realizing_value.txt\n",
      "Document Excerpt: \n",
      "lastName_0: Diamant, firstName_1: Shruti, lastName_1: Koparkar, firstName_2: Ion, lastName_2: Stoica, company_2: Anyscale, , thirdpartyid :CMP209, sessionuid :01E0763C-B5B9-416E-9F5D-44D0F4D4DB70, title :Generative AI panel: Moving beyond the hype and realizing value, description :Generative AI is motivating companies to think about how AI might reshape customer experiences, transform the way we work, and improve business productivity. The success of generative AI applications depends on many factors, including identifying the correct use case, selecting the right model, managing ML operations, optimizing ML infrastructure, and more. Generative AI panel: Moving beyond the hype and realizing value, description :Generative AI is motivating companies to think about how AI might reshape customer experiences, transform the way we work, and improve business productivity. The success of generative AI applications depends on many factors, including identifying the correct use case, selecting the right model, managing ML operations, optimizing ML infrastructure, and more. In this session, hear from a panel of experts across various industries on how to realize the full potential of this transformative technology., sessiontype :Breakout Session, venuename :Venetian, floorplanname In this session, hear from a panel of experts across various industries on how to realize the full potential of this transformative technology., sessiontype :Breakout Session, venuename :Venetian, floorplanname :Level 2, locationname :Summit Showroom, startdatetimeutc :November, 28 2023 23:30:00 -0500, enddatetimeutc :November, 29 2023 00:30:00 -0500, enddatetimeutc: November, 29 2023 00:30:00 -0500 startdatetimeutc: November, 28 2023 23:30:00 -0500 locationname: Summit Showroom floorplanname: Level 2 venuename: Venetian sessiontype: Breakout Session description: Generative AI is motivating companies to think about how AI might reshape customer experiences, transform the way we work, and improve business productivity.\n",
      "\n",
      "    </documents>\n",
      "    Based on previous documents, provide a list of data for each documents (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me to: I'm looking for a session about generative ai\n",
      "\n",
      "    Assistant:\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Based on the documents provided, here is the information for sessions related to generative AI:\\n\\nDocument 1:\\n- Speaker: Mike Chambers \\n- Venue: Mandalay Bay\\n- Date: November 29, 2023 16:30-17:30\\n- Topic: Generative AI, providing an introduction and answering questions\\n\\nDocument 2: \\n- Speakers: Shruti Diamant, Shruti Koparkar, Ion Stoica\\n- Venue: Venetian \\n- Date: November 28, 2023 23:30-00:30\\n- Topic: Moving beyond hype and realizing value from generative AI, hearing from experts across industries\\n\\nBoth sessions seem relevant to learning about generative AI. The first document provides an introductory session on the topic, while the second has experts discussing real-world applications. Let me know if you need any other details to decide which session might better suit your interests and availability.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I'm looking for a session about generative ai\"\n",
    "\n",
    "kendra_ask(kendra_index_id,llm).run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promp_definition():\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "        You are an assistant who provides recommendations on re:invent 2023 sessions, you deliver the recommendation according to their question, and also do casual conversation. \n",
    "        Use the following format:\n",
    "        History: the context of a previous conversation with the user. Useful if you need to recall past conversation, make a summary, or rephrase the answers. if History is empty it continues.\n",
    "        Question: the input question you must answer\n",
    "        Thought: you should always think about what to do, Also try to follow steps mentioned above.\n",
    "        Action: the action to take, should be one of ['re-invent-agenda-2023',\"search-session-id-information\"], provides options that have the most information that can be useful in making a decision.\n",
    "        Action Input: the input to the action\n",
    "        Observation: the result of the action\n",
    "        Thought: I now know the final answer\n",
    "        Final Answer: the final answer to the original input question, If you have more than one answer, give them all. Always reply in the original user language and human legible.\n",
    "\n",
    "        History: \n",
    "        {chat_history}\n",
    "\n",
    "        Question: {input}\n",
    "\n",
    "        Assistant:\n",
    "        {agent_scratchpad}\"\"\"\n",
    "\n",
    "    updated_prompt = PromptTemplate(\n",
    "    input_variables=['chat_history','input', 'agent_scratchpad'], template=prompt_template)\n",
    "\n",
    "    return updated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_dynamodb(id,table_name_session,llm):\n",
    "    message_history = DynamoDBChatMessageHistory(table_name=table_name_session, session_id=id)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\", llm=llm,max_token_limit=800,chat_memory=message_history, return_messages=True,ai_prefix=\"A\",human_prefix=\"H\"\n",
    "    )\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_agent(memory,tools,llm):\n",
    "    zero_shot_agent=initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    #verbose=True,\n",
    "    max_iteration=1,\n",
    "    #return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True,\n",
    "    memory=memory\n",
    ")\n",
    "    return zero_shot_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"4\"\n",
    "#query =  \"I'm looking for a session in MGM on 27th with the tag bedrock\"\n",
    "query = \"I want know about the session with id SEC234\"\n",
    "prompt_incial = promp_definition()\n",
    "qa = kendra_ask(kendra_index_id,llm)\n",
    "tools = define_tools(qa,tools)\n",
    "memory  = memory_dynamodb(session_id,table_name,llm)\n",
    "agent = langchain_agent(memory,tools,llm)\n",
    "agent.agent.llm_chain.prompt=promp_definition()\n",
    "response = agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The session with id SEC234 is titled \"Streamlining security investigations with Amazon Security Lake\". It will take place on November 29, 2023 from 21:30 - 22:30 at MGM Grand, Level 3, Chairmans 368. The session will discuss how to gain visibility for comprehensive security investigations and swift incident responses in hybrid environments using Amazon Security Lake. The speakers are Ross Warren, Matt Meck and Andrew Bienert from Seek.\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='re-invent-agenda-2023', description='useful when you want search sessions in re:Invent 2023 agenda. This will output documentation in json type. ', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method Chain.run of ConversationalRetrievalChain(memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[]), output_key=None, input_key=None, return_messages=True, human_prefix='H', ai_prefix='A', memory_key='chat_history'), callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, combine_docs_chain=StuffDocumentsChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"Human: You are an Agenda re:Invent 2023 Assistant. \\n  You are talkative and provides specific details from its context but limits it to 240 tokens.\\n  If the AI does not know the answer to a question, it truthfully says it \\n  does not know.\\n\\n  Assistant: OK, got it, I'll be a talkative truthful AI assistant.\\n\\n  Human: Here are a few documents in <documents> tags:\\n  <documents>\\n  {context}\\n  </documents>\\n  Based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me to: {question}\\n\\n  Assistant:\\n  \", template_format='f-string', validate_template=True), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x1216a6190>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-instant-v1', model_kwargs={'temperature': 0.0, 'top_p': 0.5, 'max_tokens_to_sample': 2000}, endpoint_url=None, streaming=False, provider_stop_sequence_key_name_map={'anthropic': 'stop_sequences', 'amazon': 'stopSequences', 'ai21': 'stop_sequences'}, cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n'), question_generator=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template=\"{chat_history}\\n  Human:\\n  Given the previous conversation and a follow up question below, based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me.\\n  Follow Up Question: {question}\\n  Standalone Question:\\n\\n  Assistant:\", template_format='f-string', validate_template=True), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x1216a6190>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-instant-v1', model_kwargs={'temperature': 0.0, 'top_p': 0.5, 'max_tokens_to_sample': 2000}, endpoint_url=None, streaming=False, provider_stop_sequence_key_name_map={'anthropic': 'stop_sequences', 'amazon': 'stopSequences', 'ai21': 'stop_sequences'}, cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), output_key='answer', rephrase_question=True, return_source_documents=False, return_generated_question=False, get_chat_history=None, retriever=AmazonKendraRetriever(tags=None, metadata=None, index_id='f5957a19-6741-41d0-8a62-86bbf5d691d0', region_name=None, credentials_profile_name=None, top_k=3, attribute_filter=None, page_content_formatter=<function combined_text at 0x1207e1c10>, client=<botocore.client.kendra object at 0x122012460>, user_context=None), max_tokens_limit=None)>, coroutine=None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_memory(table_name, session_id):\n",
    "\n",
    "    history = DynamoDBChatMessageHistory(table_name=table_name, session_id=session_id)\n",
    "    # memory_summary  = ConversationSummaryMemory(ai_prefix=\"A\", human_prefix=\"H\", chat_memory=history, llm=llm_instant, memory_key=\"chat_history\", return_messages=True)\n",
    "    memory = ConversationBufferMemory(ai_prefix=\"A\", human_prefix=\"H\", chat_memory=history, memory_key=\"chat_history\")\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='re-invent-agenda-2023', description='useful when you want search sessions in re:Invent 2023 agenda. This will output documentation in json type. ', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method Chain.run of ConversationalRetrievalChain(memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content=\"I'm looking for a session were elizabeth fuentes as speaker\", additional_kwargs={}, example=False), AIMessage(content=' Based on the documents provided, here is the information for sessions with Elizabeth Fuentes as a speaker:\\n\\nDocument Title: BOA212_From_Las_Vegas,_NM,_to_Las_Vegas,_NV_Elevating_customer_support.txt\\n\\nSpeakers: \\nfirstName_0: Elizabeth, lastName_0: Fuentes\\n\\nVenue: MGM Grand \\n\\nDate: Monday, November 27 2023\\n\\nSession Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\\n\\nThis session details how AI-driven solutions can transform confounding chat and voice mix-ups into positive customer experiences, with Elizabeth Fuentes listed as a speaker.', additional_kwargs={}, example=False), HumanMessage(content='Search agenda for \"Elizabeth Fuentes\" \\n', additional_kwargs={}, example=False), AIMessage(content=' Unfortunately there were no documents provided in the <documents> tags, so I do not have any session details to report based on the search term \"Elizabeth Fuentes\". My role is to truthfully respond based on the information given, and no documents were included to search through. Please provide the relevant documents if you would like me to search for session details within their contents.', additional_kwargs={}, example=False), HumanMessage(content='Search agenda for \"Elizabeth Fuentes\" \\n', additional_kwargs={}, example=False), AIMessage(content=' Here are the key details I could find for each document provided:\\n\\nDocument 1:\\nSpeakers: Elizabeth Fuentes, Guillermo Ruiz Esteban  \\nVenue: MGM Grand\\nDate: November 27, 2023 from 18:00-19:00\\nSession Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\\n\\nDocument 2: \\nVenue: Caesars Forum \\nLocation: Academy 407\\nDate: November 27, 2023 from 20:00-21:00  \\nSession Title: Enhance your document workflows with generative AI\\n\\nUnfortunately that is all the information I was able to extract from the documents provided within the given context and word limit. Let me know if you need any additional details!', additional_kwargs={}, example=False), HumanMessage(content='Elizabeth Fuentes \\n', additional_kwargs={}, example=False), AIMessage(content=' Based on the documents provided, here is a summary of the session details that include speaker information:\\n\\nDocument 1:\\n- Speakers: Elizabeth Fuentes, Guillermo Ruiz Esteban\\n- Venue: MGM Grand  \\n- Date: November 27, 2023 from 18:00-19:00\\n- Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\\n\\nDocument 2 does not include any speaker information. \\n\\nDocument 3: \\n- Speakers: Smriti Ranjan, Wrick Talukdar\\n- Venue: Caesars Forum\\n- Date: November 28, 2023 from 22:30-23:30  \\n- Title: Accelerating intelligent document processing in insurance with gen AI\\n\\nThe only document that includes Elizabeth Fuentes as a speaker is Document 1. It provides a session at the MGM Grand on November 27, 2023 about elevating customer support. Let me know if you need any other details to help choose the best session option.', additional_kwargs={}, example=False), HumanMessage(content='generative ai\\n', additional_kwargs={}, example=False), AIMessage(content=' Based on the information provided in the documents, here are the relevant details from Document 2 about a session on generative AI:\\n\\n- Venue: Caesars Forum\\n- Date: November 27, 2023 \\n- Time: 20:00-21:00\\n- Title: Enhance your document workflows with generative AI\\n\\nThis session discusses using generative AI to enhance document workflows. Unfortunately the document does not provide the location or speaker details. Let me know if you need any other information to help choose a session related to generative AI.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='H', ai_prefix='A', memory_key='chat_history'), callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, combine_docs_chain=StuffDocumentsChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"Human: You are an Agenda re:Invent 2023 Assistant. \\n  You are talkative and provides specific details from its context but limits it to 240 tokens.\\n  If the AI does not know the answer to a question, it truthfully says it \\n  does not know.\\n\\n  Assistant: OK, got it, I'll be a talkative truthful AI assistant.\\n\\n  Human: Here are a few documents in <documents> tags:\\n  <documents>\\n  {context}\\n  </documents>\\n  Based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me to: {question}\\n\\n  Assistant:\\n  \", template_format='f-string', validate_template=True), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x1216a6190>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-instant-v1', model_kwargs={'temperature': 0.0, 'top_p': 0.5, 'max_tokens_to_sample': 2000}, endpoint_url=None, streaming=False, provider_stop_sequence_key_name_map={'anthropic': 'stop_sequences', 'amazon': 'stopSequences', 'ai21': 'stop_sequences'}, cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n'), question_generator=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template=\"{chat_history}\\n  Human:\\n  Given the previous conversation and a follow up question below, based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me.\\n  Follow Up Question: {question}\\n  Standalone Question:\\n\\n  Assistant:\", template_format='f-string', validate_template=True), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x1216a6190>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-instant-v1', model_kwargs={'temperature': 0.0, 'top_p': 0.5, 'max_tokens_to_sample': 2000}, endpoint_url=None, streaming=False, provider_stop_sequence_key_name_map={'anthropic': 'stop_sequences', 'amazon': 'stopSequences', 'ai21': 'stop_sequences'}, cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), output_key='answer', rephrase_question=True, return_source_documents=False, return_generated_question=False, get_chat_history=None, retriever=AmazonKendraRetriever(tags=None, metadata=None, index_id='f5957a19-6741-41d0-8a62-86bbf5d691d0', region_name=None, credentials_profile_name=None, top_k=3, attribute_filter=None, page_content_formatter=<function combined_text at 0x1207e1c10>, client=<botocore.client.kendra object at 0x122012460>, user_context=None), max_tokens_limit=None)>, coroutine=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Human: I'm looking for a session were elizabeth fuentes as speaker\n",
      "Assistant:  Based on the documents provided, here is the information for sessions with Elizabeth Fuentes as a speaker:\n",
      "\n",
      "Document Title: BOA212_From_Las_Vegas,_NM,_to_Las_Vegas,_NV_Elevating_customer_support.txt\n",
      "\n",
      "Speakers: \n",
      "firstName_0: Elizabeth, lastName_0: Fuentes\n",
      "\n",
      "Venue: MGM Grand \n",
      "\n",
      "Date: Monday, November 27 2023\n",
      "\n",
      "Session Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\n",
      "\n",
      "This session details how AI-driven solutions can transform confounding chat and voice mix-ups into positive customer experiences, with Elizabeth Fuentes listed as a speaker.\n",
      "Human: Search agenda for \"Elizabeth Fuentes\" \n",
      "\n",
      "Assistant:  Unfortunately there were no documents provided in the <documents> tags, so I do not have any session details to report based on the search term \"Elizabeth Fuentes\". My role is to truthfully respond based on the information given, and no documents were included to search through. Please provide the relevant documents if you would like me to search for session details within their contents.\n",
      "Human: Search agenda for \"Elizabeth Fuentes\" \n",
      "\n",
      "Assistant:  Here are the key details I could find for each document provided:\n",
      "\n",
      "Document 1:\n",
      "Speakers: Elizabeth Fuentes, Guillermo Ruiz Esteban  \n",
      "Venue: MGM Grand\n",
      "Date: November 27, 2023 from 18:00-19:00\n",
      "Session Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\n",
      "\n",
      "Document 2: \n",
      "Venue: Caesars Forum \n",
      "Location: Academy 407\n",
      "Date: November 27, 2023 from 20:00-21:00  \n",
      "Session Title: Enhance your document workflows with generative AI\n",
      "\n",
      "Unfortunately that is all the information I was able to extract from the documents provided within the given context and word limit. Let me know if you need any additional details!\n",
      "Human: Elizabeth Fuentes \n",
      "\n",
      "Assistant:  Based on the documents provided, here is a summary of the session details that include speaker information:\n",
      "\n",
      "Document 1:\n",
      "- Speakers: Elizabeth Fuentes, Guillermo Ruiz Esteban\n",
      "- Venue: MGM Grand  \n",
      "- Date: November 27, 2023 from 18:00-19:00\n",
      "- Title: From Las Vegas, NM, to Las Vegas, NV: Elevating customer support\n",
      "\n",
      "Document 2 does not include any speaker information. \n",
      "\n",
      "Document 3: \n",
      "- Speakers: Smriti Ranjan, Wrick Talukdar\n",
      "- Venue: Caesars Forum\n",
      "- Date: November 28, 2023 from 22:30-23:30  \n",
      "- Title: Accelerating intelligent document processing in insurance with gen AI\n",
      "\n",
      "The only document that includes Elizabeth Fuentes as a speaker is Document 1. It provides a session at the MGM Grand on November 27, 2023 about elevating customer support. Let me know if you need any other details to help choose the best session option.\n",
      "Human: generative ai\n",
      "\n",
      "Assistant:  Based on the information provided in the documents, here are the relevant details from Document 2 about a session on generative AI:\n",
      "\n",
      "- Venue: Caesars Forum\n",
      "- Date: November 27, 2023 \n",
      "- Time: 20:00-21:00\n",
      "- Title: Enhance your document workflows with generative AI\n",
      "\n",
      "This session discusses using generative AI to enhance document workflows. Unfortunately the document does not provide the location or speaker details. Let me know if you need any other information to help choose a session related to generative AI.\n",
      "  Human:\n",
      "  Given the previous conversation and a follow up question below, based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me.\n",
      "  Follow Up Question: generative ai\n",
      "\n",
      "  Standalone Question:\n",
      "\n",
      "  Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: You are an Agenda re:Invent 2023 Assistant. \n",
      "  You are talkative and provides specific details from its context but limits it to 240 tokens.\n",
      "  If the AI does not know the answer to a question, it truthfully says it \n",
      "  does not know.\n",
      "\n",
      "  Assistant: OK, got it, I'll be a talkative truthful AI assistant.\n",
      "\n",
      "  Human: Here are a few documents in <documents> tags:\n",
      "  <documents>\n",
      "  Document Title: AIM322_Intelligent_document_processing_with_generative_AI_for_public_sector.txt\n",
      "Document Excerpt: \n",
      "Using AI-powered IDP services offers content automation, extraction, classification, and enrichment. Generative AI can augment this process by drafting reports, summarizing lengthy materials, generating accurate responses to citizen inquiries, and creating standardized templates for official documents. This talk uncovers the potential for IDP using generative AI to revolutionize document workflow in the public sector title: Intelligent document processing with generative AI for public sector sessionuid: 02DF773C-8AB0-471C-8BBF-E2EA87ABA2B8 thirdpartyid: AIM322 speakers: firstName_0: Sonali, lastName_0: Sahu, firstName_1: Cameron, lastName_1: Williams, company_1: Booz Allen Hamilton tag_name: Amazon Comprehend, Services, Independent Software Vendor ( This talk uncovers the potential for IDP using generative AI to revolutionize document workflow in the public sector title: Intelligent document processing with generative AI for public sector sessionuid: 02DF773C-8AB0-471C-8BBF-E2EA87ABA2B8 thirdpartyid: AIM322 speakers: firstName_0: Sonali, lastName_0: Sahu, firstName_1: Cameron, lastName_1: Williams, company_1: Booz Allen Hamilton tag_name: Amazon Comprehend, Services, Independent Software Vendor (ISV), Area of Interest, Solution/Systems Architect, Role, Business Intelligence, Area of Interest, Amazon Bedrock, Services, Government, Industry, Data Scientist, Role, Generative AI, Area of Interest, AI/ML, Topic, Financial Services, Industry, Monday, Day, Caesars Forum, Venue, Cross Industry, Industry, Developer/Engineer, Role, 300 - Advanced, Level, Amazon Textract, Services, Business Applications, Topic\n",
      "\n",
      "\n",
      "Document Title: AIM213_Enhance_your_document_workflows_with_generative_AI.txt\n",
      "Document Excerpt: \n",
      "AI, Area of Interest, Financial Services, Industry, Business Intelligence, Area of Interest, AI/ML, Topic, Independent Software Vendor (ISV), Area of Interest, Analytics, Topic, Monday, Day, Caesars Forum, Venue, Amazon Textract, Services, IT Executive, Role, Government, Industry, Business Executive, Role, , speakers :firstName_0: Navneeth, lastName_0: Nair, , thirdpartyid :AIM213, sessionuid :ACD8D4BE-B3EB-4147-8829-EE5770E2A54E, title :Enhance your document workflows with generative AI, description :Data classification, extraction, and analysis can be challenging for organizations that deal with volumes of documents. Traditional document processing solutions are manual, expensive, error-prone, and difficult to scale. Navneeth, lastName_0: Nair, , thirdpartyid :AIM213, sessionuid :ACD8D4BE-B3EB-4147-8829-EE5770E2A54E, title :Enhance your document workflows with generative AI, description :Data classification, extraction, and analysis can be challenging for organizations that deal with volumes of documents. Traditional document processing solutions are manual, expensive, error-prone, and difficult to scale. AWS intelligent document processing (IDP) uses industry-leading machine learning (ML) technology to quickly and accurately process data from any document or image. Generative AI complements Amazon Textract to augment your IDP workflows with additional capabilities. In this session, hear a case study of Centene, which provides access to high-quality healthcare, innovative programs, and a wide range of health solutions. Learn how Centene improves their document-centric workflows and business productivity while reducing costs using Amazon Textract and generative AI capabilities., sessiontype :Breakout Session, venuename :Caesars Forum, floorplanname :Level 1\n",
      "\n",
      "\n",
      "Document Title: AIM306_R_Intelligent_document_processing_at_scale_with_generative_AI_[REPEAT].txt\n",
      "Document Excerpt: \n",
      "Legacy OCR is tedious, expensive, and difficult to scale. AWS intelligent document processing (IDP) services help you automatically process documents quickly and accurately at scale. In this workshop, get hands-on experience to build a document processing pipeline with AWS IDP. Learn how to use generative AI to enhance document processing capabilities to deliver key insights. You must bring your laptop to participate. </p> title: Intelligent document processing at scale with generative AI [REPEAT] sessionuid: 63649688-5838-4B9F-9BF6-492974F7A223 thirdpartyid: AIM306-R speakers: firstName_0: Anjan, lastName_0: Biswas, firstName_1: Martin, lastName_1: Schade tag_name: Monday, Day, Mandalay Bay, Venue, Generative AI, Area of Interest, Cross Industry, Industry, Learn how to use generative AI to enhance document processing capabilities to deliver key insights. You must bring your laptop to participate. </p> title: Intelligent document processing at scale with generative AI [REPEAT] sessionuid: 63649688-5838-4B9F-9BF6-492974F7A223 thirdpartyid: AIM306-R speakers: firstName_0: Anjan, lastName_0: Biswas, firstName_1: Martin, lastName_1: Schade tag_name: Monday, Day, Mandalay Bay, Venue, Generative AI, Area of Interest, Cross Industry, Industry, Amazon Textract, Services, Financial Services, Industry, Solution/Systems Architect, Role, Amazon Comprehend, Services, Developer/Engineer, Role, Business Intelligence, Area of Interest, Government, Industry, Amazon Textract, Services, Financial Services, Industry, Solution/Systems Architect, Role, Amazon Comprehend, Services, Developer/Engineer, Role, Business Intelligence, Area of Interest, Government, Industry, Amazon Bedrock, Services, Data Scientist, Role, 300 - Advanced, Level, AI/ML, Topic\n",
      "\n",
      "  </documents>\n",
      "  Based on previous documents, provide a list of data for each document (If you find more than one), example: spaker veneu, date... , it's okay if you respond with just one option, the information is important so I can decide the best choise for me to:  Based on the information provided in the previous conversation and follow up question about generative AI, here is the data from Document 2:\n",
      "\n",
      "Document 2:\n",
      "- Venue: Caesars Forum  \n",
      "- Date: November 27, 2023\n",
      "- Time: 20:00-21:00\n",
      "- Title: Enhance your document workflows with generative AI\n",
      "\n",
      "This was the only document that mentioned generative AI. It discusses using generative AI to enhance document workflows, but does not include speaker details or a specific location within Caesars Forum. Let me know if you need any other information from the documents to help choose a session related to generative AI.\n",
      "\n",
      "  Assistant:\n",
      "  \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"I'm looking for a session about generative ai\",\n",
       " 'chat_history': '',\n",
       " 'output': 'Based on the details from the re:Invent 2023 agenda, I would recommend the session titled \"Enhance your document workflows with generative AI\" taking place on November 27th from 8-9pm at Caesars Forum. This session provides the most information on using generative AI to enhance document workflows, and includes specific venue and timing details. Let me know if you need anything else!'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_item_ddb(table,item):\n",
    "    response = table.put_item(Item=item)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QaToAnAgendaStack-TblReInventAgendaB6AA89B7-12IQ4AYMT82CF'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name_agenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonFilePath = \"reinvent2023v3.json\" \n",
    "with open(jsonFilePath) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag_name': 'Solution/Systems Architect, Role, IT Administrator, Role, Cross Industry, Industry, Amazon Simple Storage Service (S3), Services, Well-Architected Framework, Area of Interest, Financial Services, Industry, Security, Compliance, & Identity, Topic, Monday, Day, MGM Grand, Venue, Storage, Topic, Network & Infrastructure Security, Area of Interest, IT Professional/Technical Manager, Role, Media & Entertainment, Industry, Application Security, Area of Interest, 200 - Intermediate, Level',\n",
       " 'speakers': 'firstName_0: Sally, lastName_0: Guo, firstName_1: Will, lastName_1: Cavin',\n",
       " 'thirdpartyid': 'STG213-R',\n",
       " 'sessionuid': '600089D7-05FE-4AD2-8E6C-142C312A6ED2',\n",
       " 'title': 'Amazon S3 encryption best practices [REPEAT]',\n",
       " 'description': '<p>Strong adherence to architecture best practices and proactive controls are the foundations of data security. In this chalk talk, learn best practices for securing your data client-side, server-side, and in transit with Amazon S3 encryption options. Dive in to managing your organization’s data encryption preferences using AWS Identity and Access Management (IAM) policies and S3 bucket policies. In addition, learn how to audit your organization’s encryption profile across Amazon S3.</p>',\n",
       " 'sessiontype': 'Chalk Talk',\n",
       " 'venuename': 'MGM Grand',\n",
       " 'floorplanname': 'Level 3',\n",
       " 'locationname': '301',\n",
       " 'startdatetimeutc': 'November, 27 2023 17:00:00 -0500',\n",
       " 'enddatetimeutc': 'November, 27 2023 18:00:00 -0500',\n",
       " 'summary': 'tag_name :Solution/Systems Architect, Role, IT Administrator, Role, Cross Industry, Industry, Amazon Simple Storage Service (S3), Services, Well-Architected Framework, Area of Interest, Financial Services, Industry, Security, Compliance, & Identity, Topic, Monday, Day, MGM Grand, Venue, Storage, Topic, Network & Infrastructure Security, Area of Interest, IT Professional/Technical Manager, Role, Media & Entertainment, Industry, Application Security, Area of Interest, 200 - Intermediate, Level, , speakers :firstName_0: Sally, lastName_0: Guo, firstName_1: Will, lastName_1: Cavin, , thirdpartyid :STG213-R, sessionuid :600089D7-05FE-4AD2-8E6C-142C312A6ED2, title :Amazon S3 encryption best practices [REPEAT], description :<p>Strong adherence to architecture best practices and proactive controls are the foundations of data security. In this chalk talk, learn best practices for securing your data client-side, server-side, and in transit with Amazon S3 encryption options. Dive in to managing your organization’s data encryption preferences using AWS Identity and Access Management (IAM) policies and S3 bucket policies. In addition, learn how to audit your organization’s encryption profile across Amazon S3.</p>, sessiontype :Chalk Talk, venuename :MGM Grand, floorplanname :Level 3, locationname :301, startdatetimeutc :November, 27 2023 17:00:00 -0500, enddatetimeutc :November, 27 2023 18:00:00 -0500, ',\n",
       " 'location': 'MGM Grand, Level 3, 301'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
